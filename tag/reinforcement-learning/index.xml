<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reinforcement Learning | Ashley Hill | hill-a</title>
    <link>https://hill-a.me/tag/reinforcement-learning/</link>
      <atom:link href="https://hill-a.me/tag/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Reinforcement Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Dec 2022 12:00:00 +0000</lastBuildDate>
    <image>
      <url>https://hill-a.me/media/icon_hubbd6e63d4ed975c3d1d61fd0a96e588a_325430_512x512_fill_lanczos_center_3.png</url>
      <title>Reinforcement Learning</title>
      <link>https://hill-a.me/tag/reinforcement-learning/</link>
    </image>
    
    <item>
      <title>Online Gain Tuning Using Neural Networks: A Comparative Study</title>
      <link>https://hill-a.me/publication/agri2022/</link>
      <pubDate>Thu, 01 Dec 2022 12:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/agri2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Online Tuning of Control Parameters for Off-Road Mobile Robots: Novel Deterministic and Neural Network-Based Approaches</title>
      <link>https://hill-a.me/publication/ram2022/</link>
      <pubDate>Fri, 01 Jul 2022 12:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/ram2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Online velocity fluctuation of off-road wheeled mobile robots: A reinforcement learning approach</title>
      <link>https://hill-a.me/publication/icra2021/</link>
      <pubDate>Sun, 30 May 2021 12:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/icra2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stable-baselines3: Reliable reinforcement learning implementations</title>
      <link>https://hill-a.me/publication/stable-baselines/</link>
      <pubDate>Fri, 01 Jan 2021 12:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/stable-baselines/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Online gain setting method for path tracking using CMA-ES: Application to off-road mobile robot control</title>
      <link>https://hill-a.me/publication/iros2020/</link>
      <pubDate>Sat, 24 Oct 2020 12:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/iros2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CES-IA Reinforcement Learning Class</title>
      <link>https://hill-a.me/talk/ces-ia-reinforcement-learning-class/</link>
      <pubDate>Sat, 04 Apr 2020 09:00:00 +0000</pubDate>
      <guid>https://hill-a.me/talk/ces-ia-reinforcement-learning-class/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RL Tutorial on Stable Baselines</title>
      <link>https://hill-a.me/talk/rl-tutorial-on-stable-baselines/</link>
      <pubDate>Fri, 18 Oct 2019 09:00:00 +0000</pubDate>
      <guid>https://hill-a.me/talk/rl-tutorial-on-stable-baselines/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ICINCO presentation</title>
      <link>https://hill-a.me/talk/icinco-presentation/</link>
      <pubDate>Mon, 29 Jul 2019 12:00:00 +0000</pubDate>
      <guid>https://hill-a.me/talk/icinco-presentation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neuroevolution with CMA-ES for real-time gain tuning of a car-like robot controller</title>
      <link>https://hill-a.me/publication/icinco-2019/</link>
      <pubDate>Mon, 29 Jul 2019 12:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/icinco-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics</title>
      <link>https://hill-a.me/publication/feature-extraction/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/feature-extraction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>S-RL Toolbox: Environments, Datasets and Evaluation Metrics for State Representation Learning</title>
      <link>https://hill-a.me/publication/srl-toolbox/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://hill-a.me/publication/srl-toolbox/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stable Baselines</title>
      <link>https://hill-a.me/project/stable-baselines/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://hill-a.me/project/stable-baselines/</guid>
      <description>&lt;h1 id=&#34;stable-baselines&#34;&gt;Stable Baselines&lt;/h1&gt;
&lt;p&gt;Github repository: &lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Stable Baselines is a set of improved implementations of reinforcement learning algorithms based on OpenAI &lt;a href=&#34;https://github.com/openai/baselines/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Baselines&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can read a detailed presentation of Stable Baselines in the &lt;a href=&#34;https://medium.com/@araffin/stable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Medium article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These algorithms will make it easier for the research community and industry to replicate, refine, and identify new ideas, and will create good baselines to build projects on top of. We expect these tools will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones. We also hope that the simplicity of these tools will allow beginners to experiment with a more advanced toolset, without being buried in implementation details.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note: despite its simplicity of use, Stable Baselines (SB) assumes you have some knowledge about Reinforcement Learning (RL).&lt;/strong&gt; You should not utilize this library without some practice. To that extent, we provide good resources in the &lt;a href=&#34;https://stable-baselines.readthedocs.io/en/master/guide/rl.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; to get started with RL.&lt;/p&gt;
&lt;h2 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Stable Baselines was created in the &lt;a href=&#34;http://u2is.ensta-paristech.fr/index.php?lang=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;robotics lab U2IS&lt;/a&gt; (&lt;a href=&#34;https://flowers.inria.fr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;INRIA Flowers&lt;/a&gt; team) at &lt;a href=&#34;http://www.ensta-paristech.fr/en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ENSTA ParisTech&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Logo credits: &lt;a href=&#34;https://www.instagram.com/lucillehue/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;L.M. Tenkes&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>S-RL Toolbox</title>
      <link>https://hill-a.me/project/srl-toolbox/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://hill-a.me/project/srl-toolbox/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
